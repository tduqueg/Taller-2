{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gPRPcEyhF5Xn"
   },
   "source": [
    "# Punto 2 Taller Estadistica\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r7uLdothF4sD"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DoqHc5vMGAYq",
    "outputId": "a375b7c9-b7ce-4f88-fd75-947a7be3d96f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Configuración del dispositivo\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9s-hKxbHGDbH",
    "outputId": "1521dbe2-4145-4205-9e7b-4dcda4496e64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando Linear Classification...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Linear Classification Epoch 1/10: 100%|██████████| 782/782 [00:12<00:00, 60.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Classification Epoch 1:\n",
      "Train Loss: 0.6360\n",
      "Validation Loss: 0.4792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Linear Classification Epoch 2/10: 100%|██████████| 782/782 [00:10<00:00, 72.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Classification Epoch 2:\n",
      "Train Loss: 0.3977\n",
      "Validation Loss: 0.3318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Linear Classification Epoch 3/10: 100%|██████████| 782/782 [00:09<00:00, 84.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Classification Epoch 3:\n",
      "Train Loss: 0.2924\n",
      "Validation Loss: 0.2554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Linear Classification Epoch 4/10: 100%|██████████| 782/782 [00:11<00:00, 66.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Classification Epoch 4:\n",
      "Train Loss: 0.2369\n",
      "Validation Loss: 0.2139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Linear Classification Epoch 5/10: 100%|██████████| 782/782 [00:13<00:00, 59.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Classification Epoch 5:\n",
      "Train Loss: 0.2062\n",
      "Validation Loss: 0.1906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Linear Classification Epoch 6/10: 100%|██████████| 782/782 [00:15<00:00, 50.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Classification Epoch 6:\n",
      "Train Loss: 0.1883\n",
      "Validation Loss: 0.1769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Linear Classification Epoch 7/10: 100%|██████████| 782/782 [00:10<00:00, 72.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Classification Epoch 7:\n",
      "Train Loss: 0.1777\n",
      "Validation Loss: 0.1701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Linear Classification Epoch 8/10: 100%|██████████| 782/782 [00:09<00:00, 84.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Classification Epoch 8:\n",
      "Train Loss: 0.1711\n",
      "Validation Loss: 0.1647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Linear Classification Epoch 9/10: 100%|██████████| 782/782 [00:11<00:00, 66.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Classification Epoch 9:\n",
      "Train Loss: 0.1678\n",
      "Validation Loss: 0.1622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Linear Classification Epoch 10/10: 100%|██████████| 782/782 [00:12<00:00, 60.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Classification Epoch 10:\n",
      "Train Loss: 0.1654\n",
      "Validation Loss: 0.1619\n",
      "\n",
      "Resultados para Linear Classification:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.99      0.97    182519\n",
      "         1.0       0.86      0.53      0.66     17481\n",
      "\n",
      "    accuracy                           0.95    200000\n",
      "   macro avg       0.91      0.76      0.82    200000\n",
      "weighted avg       0.95      0.95      0.95    200000\n",
      "\n",
      "ROC AUC: 0.9746\n",
      "PR AUC: 0.7779\n",
      "\n",
      "Entrenando Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logistic Regression Epoch 1/10: 100%|██████████| 782/782 [00:10<00:00, 73.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Epoch 1:\n",
      "Train Loss: 0.5562\n",
      "Validation Loss: 0.4251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logistic Regression Epoch 2/10: 100%|██████████| 782/782 [00:09<00:00, 79.60it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Epoch 2:\n",
      "Train Loss: 0.3583\n",
      "Validation Loss: 0.3017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logistic Regression Epoch 3/10: 100%|██████████| 782/782 [00:12<00:00, 63.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Epoch 3:\n",
      "Train Loss: 0.2698\n",
      "Validation Loss: 0.2383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logistic Regression Epoch 4/10: 100%|██████████| 782/782 [00:13<00:00, 56.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Epoch 4:\n",
      "Train Loss: 0.2237\n",
      "Validation Loss: 0.2044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logistic Regression Epoch 5/10: 100%|██████████| 782/782 [00:14<00:00, 53.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Epoch 5:\n",
      "Train Loss: 0.1987\n",
      "Validation Loss: 0.1836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logistic Regression Epoch 6/10: 100%|██████████| 782/782 [00:13<00:00, 59.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Epoch 6:\n",
      "Train Loss: 0.1840\n",
      "Validation Loss: 0.1726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logistic Regression Epoch 7/10: 100%|██████████| 782/782 [00:11<00:00, 69.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Epoch 7:\n",
      "Train Loss: 0.1747\n",
      "Validation Loss: 0.1680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logistic Regression Epoch 8/10: 100%|██████████| 782/782 [00:11<00:00, 71.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Epoch 8:\n",
      "Train Loss: 0.1699\n",
      "Validation Loss: 0.1626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logistic Regression Epoch 9/10: 100%|██████████| 782/782 [00:13<00:00, 57.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Epoch 9:\n",
      "Train Loss: 0.1671\n",
      "Validation Loss: 0.1620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Logistic Regression Epoch 10/10: 100%|██████████| 782/782 [00:13<00:00, 56.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Epoch 10:\n",
      "Train Loss: 0.1649\n",
      "Validation Loss: 0.1630\n",
      "\n",
      "Resultados para Logistic Regression:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.99      0.97    182519\n",
      "         1.0       0.85      0.52      0.65     17481\n",
      "\n",
      "    accuracy                           0.95    200000\n",
      "   macro avg       0.90      0.76      0.81    200000\n",
      "weighted avg       0.95      0.95      0.95    200000\n",
      "\n",
      "ROC AUC: 0.9751\n",
      "PR AUC: 0.7747\n",
      "\n",
      "Entrenando Multiclass Logistic...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiclass Logistic Epoch 1/10: 100%|██████████| 782/782 [00:14<00:00, 53.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Logistic Epoch 1:\n",
      "Train Loss: 0.4951\n",
      "Validation Loss: 0.3157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiclass Logistic Epoch 2/10: 100%|██████████| 782/782 [00:10<00:00, 75.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Logistic Epoch 2:\n",
      "Train Loss: 0.2545\n",
      "Validation Loss: 0.2114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiclass Logistic Epoch 3/10: 100%|██████████| 782/782 [00:10<00:00, 71.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Logistic Epoch 3:\n",
      "Train Loss: 0.1927\n",
      "Validation Loss: 0.1758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiclass Logistic Epoch 4/10: 100%|██████████| 782/782 [00:12<00:00, 62.25it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Logistic Epoch 4:\n",
      "Train Loss: 0.1687\n",
      "Validation Loss: 0.1594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiclass Logistic Epoch 5/10: 100%|██████████| 782/782 [00:13<00:00, 57.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Logistic Epoch 5:\n",
      "Train Loss: 0.1566\n",
      "Validation Loss: 0.1503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiclass Logistic Epoch 6/10: 100%|██████████| 782/782 [00:12<00:00, 64.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Logistic Epoch 6:\n",
      "Train Loss: 0.1494\n",
      "Validation Loss: 0.1446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiclass Logistic Epoch 7/10: 100%|██████████| 782/782 [00:16<00:00, 47.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Logistic Epoch 7:\n",
      "Train Loss: 0.1449\n",
      "Validation Loss: 0.1408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiclass Logistic Epoch 8/10: 100%|██████████| 782/782 [00:10<00:00, 76.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Logistic Epoch 8:\n",
      "Train Loss: 0.1418\n",
      "Validation Loss: 0.1382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiclass Logistic Epoch 9/10: 100%|██████████| 782/782 [00:10<00:00, 72.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Logistic Epoch 9:\n",
      "Train Loss: 0.1398\n",
      "Validation Loss: 0.1365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Multiclass Logistic Epoch 10/10: 100%|██████████| 782/782 [00:12<00:00, 60.68it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiclass Logistic Epoch 10:\n",
      "Train Loss: 0.1385\n",
      "Validation Loss: 0.1354\n",
      "\n",
      "Resultados para Multiclass Logistic:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98    182519\n",
      "           1       0.89      0.56      0.69     17481\n",
      "\n",
      "    accuracy                           0.96    200000\n",
      "   macro avg       0.92      0.78      0.83    200000\n",
      "weighted avg       0.95      0.96      0.95    200000\n",
      "\n",
      "ROC AUC: 0.9696\n",
      "PR AUC: 0.7978\n",
      "\n",
      "Entrenando LDA...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LDA Epoch 1/10: 100%|██████████| 782/782 [00:13<00:00, 58.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Epoch 1:\n",
      "Train Loss: 0.2610\n",
      "Validation Loss: 0.1475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LDA Epoch 2/10: 100%|██████████| 782/782 [00:12<00:00, 61.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Epoch 2:\n",
      "Train Loss: 0.1398\n",
      "Validation Loss: 0.1368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LDA Epoch 3/10: 100%|██████████| 782/782 [00:10<00:00, 72.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Epoch 3:\n",
      "Train Loss: 0.1349\n",
      "Validation Loss: 0.1341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LDA Epoch 4/10: 100%|██████████| 782/782 [00:10<00:00, 73.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Epoch 4:\n",
      "Train Loss: 0.1334\n",
      "Validation Loss: 0.1341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LDA Epoch 5/10: 100%|██████████| 782/782 [00:13<00:00, 57.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Epoch 5:\n",
      "Train Loss: 0.1331\n",
      "Validation Loss: 0.1341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LDA Epoch 6/10: 100%|██████████| 782/782 [00:13<00:00, 57.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Epoch 6:\n",
      "Train Loss: 0.1335\n",
      "Validation Loss: 0.1336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LDA Epoch 7/10: 100%|██████████| 782/782 [00:13<00:00, 58.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Epoch 7:\n",
      "Train Loss: 0.1336\n",
      "Validation Loss: 0.1345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LDA Epoch 8/10: 100%|██████████| 782/782 [00:13<00:00, 56.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Epoch 8:\n",
      "Train Loss: 0.1336\n",
      "Validation Loss: 0.1336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LDA Epoch 9/10: 100%|██████████| 782/782 [00:10<00:00, 71.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Epoch 9:\n",
      "Train Loss: 0.1333\n",
      "Validation Loss: 0.1362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LDA Epoch 10/10: 100%|██████████| 782/782 [00:13<00:00, 59.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Epoch 10:\n",
      "Train Loss: 0.1332\n",
      "Validation Loss: 0.1348\n",
      "\n",
      "Resultados para LDA:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98    182519\n",
      "           1       0.89      0.62      0.73     17481\n",
      "\n",
      "    accuracy                           0.96    200000\n",
      "   macro avg       0.93      0.81      0.85    200000\n",
      "weighted avg       0.96      0.96      0.96    200000\n",
      "\n",
      "ROC AUC: 0.9670\n",
      "PR AUC: 0.8049\n"
     ]
    }
   ],
   "source": [
    "def remove_redundant_features(X, correlation_threshold=0.95):\n",
    "    \"\"\"Elimina características altamente correlacionadas.\"\"\"\n",
    "    corr_matrix = X.corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > correlation_threshold)]\n",
    "    return X.drop(columns=to_drop), to_drop\n",
    "\n",
    "def select_features(X, y, n_features=10):\n",
    "    \"\"\"Selecciona las características más importantes usando ANOVA F-value.\"\"\"\n",
    "    selector = SelectKBest(f_classif, k=n_features)\n",
    "    selector.fit(X, y)\n",
    "    feature_mask = selector.get_support()\n",
    "    selected_features = X.columns[feature_mask].tolist()\n",
    "    X_selected = pd.DataFrame(selector.transform(X), columns=selected_features)\n",
    "    return X_selected, selected_features\n",
    "\n",
    "class CreditCardDataset(Dataset):\n",
    "    def __init__(self, X, y, is_multiclass=False):\n",
    "        self.X = torch.FloatTensor(X.values if isinstance(X, pd.DataFrame) else X).to(device)\n",
    "        self.y = (torch.LongTensor(y.values if isinstance(y, pd.Series) else y) if is_multiclass \n",
    "                 else torch.FloatTensor(y.values if isinstance(y, pd.Series) else y)).to(device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Modelos\n",
    "class LinearClassification(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LinearClassification, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "\n",
    "class MulticlassLogisticRegression(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(MulticlassLogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class LDAModel(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(LDAModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, num_classes)\n",
    "        self.batch_norm = nn.BatchNorm1d(input_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.batch_norm(x)\n",
    "        return self.linear(x)\n",
    "\n",
    "def get_baseline_metrics(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Calcula métricas para un modelo baseline (clasificador aleatorio).\"\"\"\n",
    "    dummy = DummyClassifier(strategy='stratified')\n",
    "    dummy.fit(X_train, y_train)\n",
    "    y_pred = dummy.predict_proba(X_test)[:, 1]\n",
    "    return {\n",
    "        'roc_auc': roc_auc_score(y_test, y_pred),\n",
    "        'pr_auc': average_precision_score(y_test, y_pred),\n",
    "        'classification_report': classification_report(y_test, (y_pred > 0.5).astype(int))\n",
    "    }\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10, model_name=\"\"):\n",
    "    best_val_loss = float('inf')\n",
    "    best_metrics = None\n",
    "    model = model.to(device)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for batch_X, batch_y in tqdm(train_loader, desc=f'{model_name} Epoch {epoch+1}/{epochs}'):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            \n",
    "            if isinstance(criterion, nn.CrossEntropyLoss):\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                predictions = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            else:\n",
    "                outputs = outputs.squeeze()\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                predictions = outputs\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        # Validación\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_X, batch_y in val_loader:\n",
    "                outputs = model(batch_X)\n",
    "                if isinstance(criterion, nn.CrossEntropyLoss):\n",
    "                    val_loss += criterion(outputs, batch_y).item()\n",
    "                    predictions = torch.softmax(outputs, dim=1)[:, 1]\n",
    "                else:\n",
    "                    outputs = outputs.squeeze()\n",
    "                    val_loss += criterion(outputs, batch_y).item()\n",
    "                    predictions = outputs\n",
    "                \n",
    "                all_preds.extend(predictions.cpu().numpy())\n",
    "                all_labels.extend(batch_y.cpu().numpy())\n",
    "                \n",
    "        val_loss /= len(val_loader)\n",
    "        train_loss /= len(train_loader)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            predictions = np.array(all_preds)\n",
    "            true_labels = np.array(all_labels)\n",
    "            best_metrics = {\n",
    "                'roc_auc': roc_auc_score(true_labels, predictions),\n",
    "                'pr_auc': average_precision_score(true_labels, predictions),\n",
    "                'classification_report': classification_report(\n",
    "                    true_labels, \n",
    "                    (predictions > 0.5).astype(int)\n",
    "                )\n",
    "            }\n",
    "            \n",
    "        print(f'{model_name} Epoch {epoch+1}:')\n",
    "        print(f'Train Loss: {train_loss:.4f}')\n",
    "        print(f'Validation Loss: {val_loss:.4f}')\n",
    "        \n",
    "    return best_metrics\n",
    "\n",
    "def main():\n",
    "    # 1. Cargar datos\n",
    "    print(\"Cargando datos...\")\n",
    "    df = pd.read_csv('card_transdata.csv')\n",
    "    X = df.drop('fraud', axis=1)\n",
    "    y = df['fraud']\n",
    "    \n",
    "    # 2. Eliminar información redundante\n",
    "    print(\"Eliminando features redundantes...\")\n",
    "    X_cleaned, dropped_features = remove_redundant_features(X)\n",
    "    print(f\"Features eliminadas por correlación: {dropped_features}\")\n",
    "    \n",
    "    # 3. Selección de variables\n",
    "    print(\"Seleccionando features importantes...\")\n",
    "    X_selected, selected_features = select_features(X_cleaned, y)\n",
    "    print(f\"Features seleccionadas: {selected_features}\")\n",
    "    \n",
    "    # 4. Escalado de características\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_selected)\n",
    "    X_scaled = pd.DataFrame(X_scaled, columns=X_selected.columns)\n",
    "    \n",
    "    # 5. Split inicial para test final\n",
    "    print(\"Separando datos en train y test...\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # 6. Obtener métricas baseline\n",
    "    print(\"Calculando métricas baseline...\")\n",
    "    baseline_metrics = get_baseline_metrics(X_train, X_test, y_train, y_test)\n",
    "    print(\"\\nMétricas Baseline:\")\n",
    "    print(f\"ROC AUC Baseline: {baseline_metrics['roc_auc']:.4f}\")\n",
    "    print(f\"PR AUC Baseline: {baseline_metrics['pr_auc']:.4f}\")\n",
    "    \n",
    "    # 7. Crear datasets y dataloaders\n",
    "    batch_size = 1024\n",
    "    \n",
    "    # 8. Configurar y entrenar modelos\n",
    "    models = {\n",
    "        'Linear Classification': {\n",
    "            'model': LinearClassification(X_train.shape[1]),\n",
    "            'criterion': nn.BCELoss(),\n",
    "            'is_multiclass': False\n",
    "        },\n",
    "        'Logistic Regression': {\n",
    "            'model': LogisticRegression(X_train.shape[1]),\n",
    "            'criterion': nn.BCELoss(),\n",
    "            'is_multiclass': False\n",
    "        },\n",
    "        'Multiclass Logistic': {\n",
    "            'model': MulticlassLogisticRegression(X_train.shape[1], 2),\n",
    "            'criterion': nn.CrossEntropyLoss(),\n",
    "            'is_multiclass': True\n",
    "        },\n",
    "        'LDA': {\n",
    "            'model': LDAModel(X_train.shape[1], 2),\n",
    "            'criterion': nn.CrossEntropyLoss(),\n",
    "            'is_multiclass': True\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Entrenar y evaluar cada modelo\n",
    "    results = {}\n",
    "    \n",
    "    for name, config in models.items():\n",
    "        print(f\"\\nEntrenando {name}...\")\n",
    "        model = config['model'].to(device)\n",
    "        criterion = config['criterion']\n",
    "        is_multiclass = config['is_multiclass']\n",
    "        \n",
    "        # Crear datasets específicos para cada modelo\n",
    "        train_dataset = CreditCardDataset(X_train, y_train, is_multiclass)\n",
    "        test_dataset = CreditCardDataset(X_test, y_test, is_multiclass)\n",
    "        \n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "        \n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        results[name] = train_model(\n",
    "            model,\n",
    "            train_loader,\n",
    "            test_loader,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            epochs=10,\n",
    "            model_name=name\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nResultados para {name}:\")\n",
    "        print(\"Classification Report:\")\n",
    "        print(results[name]['classification_report'])\n",
    "        print(f\"ROC AUC: {results[name]['roc_auc']:.4f}\")\n",
    "        print(f\"PR AUC: {results[name]['pr_auc']:.4f}\")\n",
    "    \n",
    "    # 9. Comparar todos los modelos\n",
    "    print(\"\\nComparación final de modelos:\")\n",
    "    print(\"-----------------------------\")\n",
    "    print(\"\\nMétricas Baseline:\")\n",
    "    print(f\"ROC AUC Baseline: {baseline_metrics['roc_auc']:.4f}\")\n",
    "    print(f\"PR AUC Baseline: {baseline_metrics['pr_auc']:.4f}\")\n",
    "    for name, metrics in results.items():\n",
    "        print(f\"\\n{name}:\")\n",
    "        print(f\"ROC AUC: {metrics['roc_auc']:.4f}\")\n",
    "        print(f\"PR AUC: {metrics['pr_auc']:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
