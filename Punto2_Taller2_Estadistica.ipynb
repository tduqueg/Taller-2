{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Punto 2 Taller Estadistica\n",
        "\n"
      ],
      "metadata": {
        "id": "gPRPcEyhF5Xn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r7uLdothF4sD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, roc_auc_score, average_precision_score\n",
        "from tqdm import tqdm\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuración del dispositivo\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DoqHc5vMGAYq",
        "outputId": "a375b7c9-b7ce-4f88-fd75-947a7be3d96f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset personalizado\n",
        "class CreditCardDataset(Dataset):\n",
        "    def __init__(self, X, y, is_multiclass=False):\n",
        "        self.X = torch.FloatTensor(X).to(device)\n",
        "        # Usar LongTensor para multiclass, FloatTensor para binario\n",
        "        self.y = torch.LongTensor(y).to(device) if is_multiclass else torch.FloatTensor(y).to(device)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# Modelo de Regresión Lineal para Clasificación\n",
        "class LinearClassification(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(LinearClassification, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.sigmoid(self.linear(x))\n",
        "\n",
        "# Modelo de Regresión Logística\n",
        "class LogisticRegression(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(LogisticRegression, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.sigmoid(self.linear(x))\n",
        "\n",
        "# Modelo de Regresión Logística Multiclase\n",
        "class MulticlassLogisticRegression(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super(MulticlassLogisticRegression, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)  # No aplicamos softmax aquí ya que CrossEntropyLoss lo incluye\n",
        "\n",
        "# Modelo de LDA\n",
        "class LDAModel(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super(LDAModel, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, num_classes)\n",
        "        self.batch_norm = nn.BatchNorm1d(input_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.batch_norm(x)\n",
        "        return self.linear(x)  # No aplicamos softmax aquí ya que CrossEntropyLoss lo incluye\n",
        "\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, epochs=10, model_name=\"\"):\n",
        "    best_val_loss = float('inf')\n",
        "    best_metrics = None\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "\n",
        "        for batch_X, batch_y in tqdm(train_loader, desc=f'{model_name} Epoch {epoch+1}/{epochs}'):\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(batch_X)\n",
        "\n",
        "            # Manejar diferentes tipos de salidas según el criterio\n",
        "            if isinstance(criterion, nn.CrossEntropyLoss):\n",
        "                loss = criterion(outputs, batch_y)\n",
        "                predictions = torch.softmax(outputs, dim=1)[:, 1]\n",
        "            else:\n",
        "                outputs = outputs.squeeze()\n",
        "                loss = criterion(outputs, batch_y)\n",
        "                predictions = outputs\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # Validación\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in val_loader:\n",
        "                outputs = model(batch_X)\n",
        "                if isinstance(criterion, nn.CrossEntropyLoss):\n",
        "                    val_loss += criterion(outputs, batch_y).item()\n",
        "                    predictions = torch.softmax(outputs, dim=1)[:, 1]\n",
        "                else:\n",
        "                    outputs = outputs.squeeze()\n",
        "                    val_loss += criterion(outputs, batch_y).item()\n",
        "                    predictions = outputs\n",
        "\n",
        "                all_preds.extend(predictions.cpu().numpy())\n",
        "                all_labels.extend(batch_y.cpu().numpy())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            predictions = np.array(all_preds)\n",
        "            true_labels = np.array(all_labels)\n",
        "            best_metrics = {\n",
        "                'roc_auc': roc_auc_score(true_labels, predictions),\n",
        "                'pr_auc': average_precision_score(true_labels, predictions),\n",
        "                'classification_report': classification_report(\n",
        "                    true_labels,\n",
        "                    (predictions > 0.5).astype(int)\n",
        "                )\n",
        "            }\n",
        "\n",
        "        print(f'{model_name} Epoch {epoch+1}:')\n",
        "        print(f'Train Loss: {train_loss:.4f}')\n",
        "        print(f'Validation Loss: {val_loss:.4f}')\n",
        "\n",
        "    return best_metrics\n",
        "\n",
        "def main():\n",
        "    # Cargar y preparar datos\n",
        "    df = pd.read_csv('card_transdata.csv')\n",
        "    X = df.drop('fraud', axis=1).values\n",
        "    y = df['fraud'].values\n",
        "\n",
        "    # Escalado de características\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Split de datos\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # Crear datasets y dataloaders\n",
        "    batch_size = 1024\n",
        "\n",
        "    # Configurar modelos y sus respectivos datasets\n",
        "    models = {\n",
        "        'Linear Classification': {\n",
        "            'model': LinearClassification(X_train.shape[1]),\n",
        "            'criterion': nn.BCELoss(),\n",
        "            'is_multiclass': False\n",
        "        },\n",
        "        'Logistic Regression': {\n",
        "            'model': LogisticRegression(X_train.shape[1]),\n",
        "            'criterion': nn.BCELoss(),\n",
        "            'is_multiclass': False\n",
        "        },\n",
        "        'Multiclass Logistic': {\n",
        "            'model': MulticlassLogisticRegression(X_train.shape[1], 2),\n",
        "            'criterion': nn.CrossEntropyLoss(),\n",
        "            'is_multiclass': True\n",
        "        },\n",
        "        'LDA': {\n",
        "            'model': LDAModel(X_train.shape[1], 2),\n",
        "            'criterion': nn.CrossEntropyLoss(),\n",
        "            'is_multiclass': True\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Entrenar y evaluar cada modelo\n",
        "    results = {}\n",
        "\n",
        "    for name, config in models.items():\n",
        "        print(f\"\\nEntrenando {name}...\")\n",
        "        model = config['model'].to(device)\n",
        "        criterion = config['criterion']\n",
        "        is_multiclass = config['is_multiclass']\n",
        "\n",
        "        # Crear datasets específicos para cada modelo\n",
        "        train_dataset = CreditCardDataset(X_train, y_train, is_multiclass)\n",
        "        test_dataset = CreditCardDataset(X_test, y_test, is_multiclass)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "        results[name] = train_model(\n",
        "            model,\n",
        "            train_loader,\n",
        "            test_loader,\n",
        "            criterion,\n",
        "            optimizer,\n",
        "            epochs=10,\n",
        "            model_name=name\n",
        "        )\n",
        "\n",
        "        print(f\"\\nResultados para {name}:\")\n",
        "        print(\"Classification Report:\")\n",
        "        print(results[name]['classification_report'])\n",
        "        print(f\"ROC AUC: {results[name]['roc_auc']:.4f}\")\n",
        "        print(f\"PR AUC: {results[name]['pr_auc']:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9s-hKxbHGDbH",
        "outputId": "1521dbe2-4145-4205-9e7b-4dcda4496e64"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Entrenando Linear Classification...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Classification Epoch 1/10: 100%|██████████| 782/782 [00:12<00:00, 60.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Classification Epoch 1:\n",
            "Train Loss: 0.6360\n",
            "Validation Loss: 0.4792\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Classification Epoch 2/10: 100%|██████████| 782/782 [00:10<00:00, 72.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Classification Epoch 2:\n",
            "Train Loss: 0.3977\n",
            "Validation Loss: 0.3318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Classification Epoch 3/10: 100%|██████████| 782/782 [00:09<00:00, 84.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Classification Epoch 3:\n",
            "Train Loss: 0.2924\n",
            "Validation Loss: 0.2554\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Classification Epoch 4/10: 100%|██████████| 782/782 [00:11<00:00, 66.55it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Classification Epoch 4:\n",
            "Train Loss: 0.2369\n",
            "Validation Loss: 0.2139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Classification Epoch 5/10: 100%|██████████| 782/782 [00:13<00:00, 59.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Classification Epoch 5:\n",
            "Train Loss: 0.2062\n",
            "Validation Loss: 0.1906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Classification Epoch 6/10: 100%|██████████| 782/782 [00:15<00:00, 50.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Classification Epoch 6:\n",
            "Train Loss: 0.1883\n",
            "Validation Loss: 0.1769\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Classification Epoch 7/10: 100%|██████████| 782/782 [00:10<00:00, 72.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Classification Epoch 7:\n",
            "Train Loss: 0.1777\n",
            "Validation Loss: 0.1701\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Classification Epoch 8/10: 100%|██████████| 782/782 [00:09<00:00, 84.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Classification Epoch 8:\n",
            "Train Loss: 0.1711\n",
            "Validation Loss: 0.1647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Classification Epoch 9/10: 100%|██████████| 782/782 [00:11<00:00, 66.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Classification Epoch 9:\n",
            "Train Loss: 0.1678\n",
            "Validation Loss: 0.1622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Linear Classification Epoch 10/10: 100%|██████████| 782/782 [00:12<00:00, 60.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Classification Epoch 10:\n",
            "Train Loss: 0.1654\n",
            "Validation Loss: 0.1619\n",
            "\n",
            "Resultados para Linear Classification:\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.96      0.99      0.97    182519\n",
            "         1.0       0.86      0.53      0.66     17481\n",
            "\n",
            "    accuracy                           0.95    200000\n",
            "   macro avg       0.91      0.76      0.82    200000\n",
            "weighted avg       0.95      0.95      0.95    200000\n",
            "\n",
            "ROC AUC: 0.9746\n",
            "PR AUC: 0.7779\n",
            "\n",
            "Entrenando Logistic Regression...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Logistic Regression Epoch 1/10: 100%|██████████| 782/782 [00:10<00:00, 73.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Epoch 1:\n",
            "Train Loss: 0.5562\n",
            "Validation Loss: 0.4251\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Logistic Regression Epoch 2/10: 100%|██████████| 782/782 [00:09<00:00, 79.60it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Epoch 2:\n",
            "Train Loss: 0.3583\n",
            "Validation Loss: 0.3017\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Logistic Regression Epoch 3/10: 100%|██████████| 782/782 [00:12<00:00, 63.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Epoch 3:\n",
            "Train Loss: 0.2698\n",
            "Validation Loss: 0.2383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Logistic Regression Epoch 4/10: 100%|██████████| 782/782 [00:13<00:00, 56.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Epoch 4:\n",
            "Train Loss: 0.2237\n",
            "Validation Loss: 0.2044\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Logistic Regression Epoch 5/10: 100%|██████████| 782/782 [00:14<00:00, 53.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Epoch 5:\n",
            "Train Loss: 0.1987\n",
            "Validation Loss: 0.1836\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Logistic Regression Epoch 6/10: 100%|██████████| 782/782 [00:13<00:00, 59.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Epoch 6:\n",
            "Train Loss: 0.1840\n",
            "Validation Loss: 0.1726\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Logistic Regression Epoch 7/10: 100%|██████████| 782/782 [00:11<00:00, 69.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Epoch 7:\n",
            "Train Loss: 0.1747\n",
            "Validation Loss: 0.1680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Logistic Regression Epoch 8/10: 100%|██████████| 782/782 [00:11<00:00, 71.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Epoch 8:\n",
            "Train Loss: 0.1699\n",
            "Validation Loss: 0.1626\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Logistic Regression Epoch 9/10: 100%|██████████| 782/782 [00:13<00:00, 57.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Epoch 9:\n",
            "Train Loss: 0.1671\n",
            "Validation Loss: 0.1620\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Logistic Regression Epoch 10/10: 100%|██████████| 782/782 [00:13<00:00, 56.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Epoch 10:\n",
            "Train Loss: 0.1649\n",
            "Validation Loss: 0.1630\n",
            "\n",
            "Resultados para Logistic Regression:\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.96      0.99      0.97    182519\n",
            "         1.0       0.85      0.52      0.65     17481\n",
            "\n",
            "    accuracy                           0.95    200000\n",
            "   macro avg       0.90      0.76      0.81    200000\n",
            "weighted avg       0.95      0.95      0.95    200000\n",
            "\n",
            "ROC AUC: 0.9751\n",
            "PR AUC: 0.7747\n",
            "\n",
            "Entrenando Multiclass Logistic...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Multiclass Logistic Epoch 1/10: 100%|██████████| 782/782 [00:14<00:00, 53.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass Logistic Epoch 1:\n",
            "Train Loss: 0.4951\n",
            "Validation Loss: 0.3157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Multiclass Logistic Epoch 2/10: 100%|██████████| 782/782 [00:10<00:00, 75.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass Logistic Epoch 2:\n",
            "Train Loss: 0.2545\n",
            "Validation Loss: 0.2114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Multiclass Logistic Epoch 3/10: 100%|██████████| 782/782 [00:10<00:00, 71.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass Logistic Epoch 3:\n",
            "Train Loss: 0.1927\n",
            "Validation Loss: 0.1758\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Multiclass Logistic Epoch 4/10: 100%|██████████| 782/782 [00:12<00:00, 62.25it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass Logistic Epoch 4:\n",
            "Train Loss: 0.1687\n",
            "Validation Loss: 0.1594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Multiclass Logistic Epoch 5/10: 100%|██████████| 782/782 [00:13<00:00, 57.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass Logistic Epoch 5:\n",
            "Train Loss: 0.1566\n",
            "Validation Loss: 0.1503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Multiclass Logistic Epoch 6/10: 100%|██████████| 782/782 [00:12<00:00, 64.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass Logistic Epoch 6:\n",
            "Train Loss: 0.1494\n",
            "Validation Loss: 0.1446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Multiclass Logistic Epoch 7/10: 100%|██████████| 782/782 [00:16<00:00, 47.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass Logistic Epoch 7:\n",
            "Train Loss: 0.1449\n",
            "Validation Loss: 0.1408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Multiclass Logistic Epoch 8/10: 100%|██████████| 782/782 [00:10<00:00, 76.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass Logistic Epoch 8:\n",
            "Train Loss: 0.1418\n",
            "Validation Loss: 0.1382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Multiclass Logistic Epoch 9/10: 100%|██████████| 782/782 [00:10<00:00, 72.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass Logistic Epoch 9:\n",
            "Train Loss: 0.1398\n",
            "Validation Loss: 0.1365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Multiclass Logistic Epoch 10/10: 100%|██████████| 782/782 [00:12<00:00, 60.68it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass Logistic Epoch 10:\n",
            "Train Loss: 0.1385\n",
            "Validation Loss: 0.1354\n",
            "\n",
            "Resultados para Multiclass Logistic:\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98    182519\n",
            "           1       0.89      0.56      0.69     17481\n",
            "\n",
            "    accuracy                           0.96    200000\n",
            "   macro avg       0.92      0.78      0.83    200000\n",
            "weighted avg       0.95      0.96      0.95    200000\n",
            "\n",
            "ROC AUC: 0.9696\n",
            "PR AUC: 0.7978\n",
            "\n",
            "Entrenando LDA...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LDA Epoch 1/10: 100%|██████████| 782/782 [00:13<00:00, 58.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDA Epoch 1:\n",
            "Train Loss: 0.2610\n",
            "Validation Loss: 0.1475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LDA Epoch 2/10: 100%|██████████| 782/782 [00:12<00:00, 61.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDA Epoch 2:\n",
            "Train Loss: 0.1398\n",
            "Validation Loss: 0.1368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LDA Epoch 3/10: 100%|██████████| 782/782 [00:10<00:00, 72.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDA Epoch 3:\n",
            "Train Loss: 0.1349\n",
            "Validation Loss: 0.1341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LDA Epoch 4/10: 100%|██████████| 782/782 [00:10<00:00, 73.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDA Epoch 4:\n",
            "Train Loss: 0.1334\n",
            "Validation Loss: 0.1341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LDA Epoch 5/10: 100%|██████████| 782/782 [00:13<00:00, 57.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDA Epoch 5:\n",
            "Train Loss: 0.1331\n",
            "Validation Loss: 0.1341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LDA Epoch 6/10: 100%|██████████| 782/782 [00:13<00:00, 57.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDA Epoch 6:\n",
            "Train Loss: 0.1335\n",
            "Validation Loss: 0.1336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LDA Epoch 7/10: 100%|██████████| 782/782 [00:13<00:00, 58.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDA Epoch 7:\n",
            "Train Loss: 0.1336\n",
            "Validation Loss: 0.1345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LDA Epoch 8/10: 100%|██████████| 782/782 [00:13<00:00, 56.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDA Epoch 8:\n",
            "Train Loss: 0.1336\n",
            "Validation Loss: 0.1336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LDA Epoch 9/10: 100%|██████████| 782/782 [00:10<00:00, 71.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDA Epoch 9:\n",
            "Train Loss: 0.1333\n",
            "Validation Loss: 0.1362\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LDA Epoch 10/10: 100%|██████████| 782/782 [00:13<00:00, 59.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LDA Epoch 10:\n",
            "Train Loss: 0.1332\n",
            "Validation Loss: 0.1348\n",
            "\n",
            "Resultados para LDA:\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98    182519\n",
            "           1       0.89      0.62      0.73     17481\n",
            "\n",
            "    accuracy                           0.96    200000\n",
            "   macro avg       0.93      0.81      0.85    200000\n",
            "weighted avg       0.96      0.96      0.96    200000\n",
            "\n",
            "ROC AUC: 0.9670\n",
            "PR AUC: 0.8049\n"
          ]
        }
      ]
    }
  ]
}